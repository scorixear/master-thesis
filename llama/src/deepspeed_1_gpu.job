#!/bin/bash
#SBATCH --job-name=deepspeed-llama7b-1gpu       # name
#SBATCH --nodes=1                           # nodes
#SBATCH --ntasks-per-node=1                 # crucial - only 1 task per dist per node!
#SBATCH --cpus-per-task=4                   # number of cores per tasks
#SBATCH --partition=clara
#SBATCH --gres=gpu:v100:1                   # number of gpus
#SBATCH --output=%x-%j.out                  # output file name
#SBATCH --mail-type=ALL

module load Python
module load PyTorch
srun pip install --user -r requirements.txt

export GPUS_PER_NODE=1
export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASER_PORT=9906

srun --jobid $SLURM_JOBID bash -c "python -m torch.distributed.run \
--nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \
--master_addr $MASTER_ADDR --master_port $MASTER_PORT 03_train_llama.py\
--model_path llama_model/7B --use_fast_tokenizer true --torch_dtype auto --low_cpu_mem_usage true \
--train_file input/health_information_systems_epub.md \
--max_train_samples 1000 --validation_split_percentage 5 --preprocessing_num_workers 1 --keep_linebreaks true \
--output_dir trained/7B --overwrite_output_dir false --do_train true --do_eval true \
--evaluation_strategy steps --eval_steps 100 \
--learning_rate 3e-4 --weight_decay 0.1 --adam_beta1 0.9 --adam_beta2 0.95 --adam_epsilon 1e-8 \
--max_grad_norm 1.0 --num_train_epochs 3 --lr_scheduler_type cosine --warmup_steps 0 --log_level passive \
--save_strategy steps --save_steps 500 --save_total_limit 1 \
--no_cuda false --seed 42 \
--fp16 true --half_precision_backend auto --local_rank $SLURM_PROCID --ddp_backend nccl \
--deepspeed ds_config.json --optim adamw_hf"