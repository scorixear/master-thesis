%*****************************************
\chapter{Diskussion}\label{ch:discussion}
%*****************************************
Die Ergebnisse dieser Arbeit zeigen, dass ein Continual Pretraining die Leistung eines Modells bei der Beantwortung von Fragen verbessern kann.
Dennoch erreichte das hier trainierte Modell eine maximale Leistung von \num{0.3} MakroF1, was nicht mit derzeit verfügbaren Modellen wie GPT4 vergleichbar ist.
Um diese Leistung zu erreichen, werden in \cref{ch:futurework} einige Ansätze vorgestellt, die in zukünftigen Arbeiten untersucht werden können.

\section{Grenzen der Modelle}
Die hier vorgestellten Modelle stellen eine Momentaufnahme in einer bestimmten Umgebung dar, können aber keine generelle Aussage über die zu erwartende Leistung von Continual Pretraining machen.
Das Training der Modelle ist durch die Ressourcenanforderungen begrenzt und stellt auch nicht die optimale Leistung dar, die ein Llama 2 Modell erreichen kann.\\

Während des Trainings wurde ein Zustand der Überanpassung erreicht, wobei der genaue Zeitpunkt nicht bestimmt werden konnte.
Bereits nach 3 Epochen ist ein deutlicher Anstieg der Fehlerwerte gegenüber dem Validierungsdatensatz zu erkennen, so dass davon auszugehen ist, dass dies bereits vorher begonnen hat.
Zudem wurde die Unterteilung des Fortschritts nur in 1, 3, 5 und 10 Epochen vorgenommen, weshalb nicht ausgeschlossen werden kann, dass z.B. bei 4 Epochen bessere Ergebnisse erzielt werden können.\\

Auch die geringe Datenmenge für das Training reduziert die mögliche Leistung in allen Kriterien.
Kleine Datenmengen führen zu Überanpassung und stellen Informationen in zu wenig unterschiedlichen Ausprägungen dar, was die Generalisierbarkeit des Modells verringert.\\

Die Evaluierung des Modells erfolgte anhand von \num{95} Fragen.
Auch dieser Fragenkatalog ist kleiner als erwartet und enthält meist ähnliche Wissensfragen in nur einer Formulierung.
Insbesondere die Fragen aus der schriftlichen Prüfung des Moduls \enquote{Informationssysteme im Gesundheitswesen} umfassen insgesamt nur 9 Fragen und unterliegen damit sehr starken Schwankungen.\\

Die Ergebnisse der Evaluation zeigen eine Tendenz zur Verbesserung, die trainierten Modelle selbst sind in diesem Zustand jedoch nicht verwendbar.
Dies liegt zum einen an dem fehlenden Finetuning, welches die Gefährlichkeit des Modells deutlich erhöht, da es schädliche und falsche Antworten generieren kann, zum anderen an der allgemeinen Formulierung der Antworten.
Wie bereits in \cref{ch:results} gezeigt, beenden Modelle ihre Antwort nicht eindeutig mit einem Token, sondern generieren fortlaufend Text.
Daher enthalten alle generierten Antworten zumeist am Ende zitierte Textpassagen, die keinen Bezug zur Frage haben.
Dies erschwert die Verwendung dieses Modells erheblich.
Abhilfe schafft hier das bereits erwähnte Finetuning, bei dem einem Modell abschließende Token beigebracht werden, nach denen die Generierung gestoppt werden kann.

\section{Probleme bei Kernfragen}
Das Thema Informationssysteme im Gesundheitswesen und damit auch der hier verwendete Evaluationsdatensatz enthalten grundlegende Kerninformationen,
die in ihrem Verständnis wichtiger sind als anderes Wissen. Dazu gehören z.B. die Definition von Daten, Information und Wissen, die Definition eines Informationssystems, so dass Menschen Teil des Systems sind, oder die Unterscheidung zwischen Anwendungssystemen und Softwareprodukten (ein Anwendungssystem ist die Installation und Nutzung eines Softwareprodukts durch Akteure, deren Rollen und Aufgaben).\\

Diese grundlegenden Wissenfragen werden in der Literatur zu diesem Thema unterschiedlich definiert und sollte von den Modellen mit dem Wissen aus dem Buch von \citet{bb} beantwortet werden.
Auch widersprechen einige Definitionen aus dem Buch der Definition aus dem allgemeinen Sprachgebrauch. Auch hier ist eine Beantwortung mit dem Wissen aus dem Buch erforderlich.\\

Die hier trainierten Modelle wurden jedoch auf Literatur vortrainiert, die durchaus widersprüchliches Wissen zum Buch enthält.
So beantworten Modelle vor Epoche 5 Kernfragen wie \enquote{Was ist ein Informationssystem} oft falsch und beziehen den Menschen nicht mit ein.
Mit fortschreitender Epoche verbessert sich dieses Verhalten, da die Modelle den Zustand der Überanpassung erreichen und nur noch Wissen aus dem Buch zitieren.
Dennoch kann eine grundsätzliche Falschbeantwortung von Kernfragen in dieser Arbeit nicht ausgeschlossen werden.
Hier wäre eine genauere Evaluierung mit nur Kernfragen notwendig, um die Leistung der Modelle in diesem Bereich zu untersuchen.\\

\section{Bewertung der Fragen mit Prüfungspunkten}
Zur Berechnung des Kriteriums Korrektheit wurden jeder Frage drei Werte zugeordnet: die Anzahl der korrekten Antworten des Modells, die Anzahl der Antworten des Modells im Allgemeinen und die Anzahl der erwarteten Antworten für diese Frage.
Anhand dieser Werte wurden die F1- und MakroF1-Werte der Modelle berechnet.\\

Da der Evaluationsdatensatz jedoch größtenteils aus Prüfungsfragen besteht, wäre hier auch eine Auswertung der Fragen nach den Original-Prüfungspunkten möglich.
Dadurch würden schwierigere Fragen bzw. Fragen mit mehr Antworten stärker gewichtet und hätten somit einen größeren Einfluss auf die Leistung der Modelle.
Diese Art der Auswertung könnte die Modellleistung in den Kontext der menschlichen Leistung stellen und die Aussagen über die Modellleistung nachvollziehbarer machen.
