%*****************************************
\chapter{Ausführung der Lösung}\label{ch:solution}
%*****************************************

Zur Durchführung des Trainings unterteilt sich die Lösung in 6 Schritte.
Diese werden im Folgenden näher erläutert. Die Verwendung von Techniken und Bibliotheken erfolgt ebenso abgetrennt zu jedem Schritt.
Eine grobe Abfolge der Schritte ist wie folgt:
\begin{itemize}
    \item Schritt 1: Herunterladen des Modells
    \item Schritt 2: Umwandlung des Modells in ein kompatibles Format
    \item Schritt 3: Training des Modells
    \item Schritt 4: Generierung von Antworten auf Evaluierungsdatensatz
    \item Schritt 5: Bewertung der generierten Antworten
    \item Schritt 6: Evaluierung auf Basis der Bewertungen
\end{itemize}

\section{Schritt 1: Herunterladen des Modells}
Die LLaMA Modelle sind im Rahmen einer nicht-kommerziellen Lizenz, welche sich auf Forschung fokusiert, freigegeben. Zugang zu den Modellen wird von Fall zu Fall auf Anfrage gewährt. Diese Anfrage wurde im Rahmen dieser Arbeit gestellt und bestätigt.
Daraufhin kann ein vorbereitetes Skript der Autoren genutzt werden, um die trainieren Parameter des Modells herunterzuladen.
Der Skript benötigt eine explizite \ac{url}, die nach einer vorgegebenen Zeit von einer Woche nach Freigabe der Modelle ungültig wird. Aus diesem Grund ist diese \ac{url} nicht im Skript enthalten.

\section{Schritt 2: Umwandlung des Modells in ein kompatibles Format}
Das Training des Modells basiert auf zwei grundlegenden Bibliotheken: der Transformers Bibliothek von Huggingface und der DeepSpeed Bibliothek von Microsoft.
Diese Bibliotheken, insbesondere Transformers erleichtern den Entwicklungsprozess enorm und bieten eine große Abstraktion. Jedoch können Sie nur mit Modellen arbeiten, welche in einer für die Transformers-Bibliothek verständlichen Form vorhanden sind.
Aus diesem Grund wird das heruntergeladene Modell mit Hilfe eines Skriptes von Huggingface in die genannte kompatible Form umgewandelt werden.
Während dieser Umwandlung muss das Modell vollständig in den \ac{ram} des ausführenden Computers geladen werden. Bei dem LLaMA 7B Modell sind hier also über 14 GB RAM notwendig.
Die Umwandlung dauerte auf einem Computer mit 32 GB RAM und einem AMD Ryzen 7 5800X Prozessor ca. 30 Minuten.

\section{Schritt 3: Training des Modells}


%
% - genertierter Text ohne Stopzeichen: Stopzeichen händisch nach NewLine (double Newline?)
% - requirements txt erstellen
% - DeepSpeed Config mit https://www.deepspeed.ai/docs/config-json/#batch-size-related-parameters+
% - Nutzung von ZeRO Stage2 optimization
% - llama2 7b genutzt
% - dataclasses um Datensatz einzulesen
% - Kleinere Block_size für Loss Scaling
% - BF16 nur auf AMP GPU Architektur möglich (hier nicht)
% - Deutlich mehr RAM erforderlich (180GB?)
% - Leistungen bei 11s/it von 3600 Iteration = 11h Training
% - Evaluation aller 50 Iterations, Saves aller 100 Iterations
% - Stage2/3 ohne CPU Offloading führt zu OOM
% - 3 Epochen = 14s/it 1800 = 7h Training (256 Block_size)
% - Deepspeed Launcher mit 3 GPUs (32GB v100, 1 Maschine)
% - Weitere Hyperparameter aus Llama2 Modell
% - Nutzung von Epub anstelle Word Datei da bessere Konvertierung
% - keine nutung von chat Version (verlernt Human Reinforcment)